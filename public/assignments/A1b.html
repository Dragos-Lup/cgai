<style>
    /* Custom styles for headings */
    .h1-custom {
        font-size: 2.25rem; /* equivalent to text-4xl */
        font-weight: 700; /* equivalent to font-bold */
        margin-bottom: 1.5rem; /* equivalent to mb-6 */
    }

    .h2-custom {
        font-size: 1.5rem; /* equivalent to text-2xl */
        font-weight: 600; /* equivalent to font-semibold */
        margin-top: 1.5rem; /* equivalent to mt-6 */
        margin-bottom: 1rem; /* equivalent to mb-4 */
    }

    .h3-custom {
        font-size: 1.25rem; /* equivalent to text-xl */
        font-weight: 500; /* equivalent to font-medium */
        margin-top: 1rem; /* equivalent to mt-4 */
        margin-bottom: 0.5rem; /* equivalent to mb-2 */
    }

    .h4-custom {
        font-size: 1.05rem; /* equivalent to text-xl */
        font-weight: 500; /* equivalent to font-medium */
        margin-top: 1rem; /* equivalent to mt-4 */
        margin-bottom: 0.5rem; /* equivalent to mb-2 */
    }

    /* Styling for code elements */
    .code-inline {
        font-family: 'Fira Code', Consolas, 'Courier New', monospace;
        font-size: 1.1rem;
        font-weight: bold;
    }

    .link-inline {
        text-decoration: underline;  /* Ensures the links are underlined */
        color: #1d4ed8;              /* Sets the blue color for the links */
        font-family: 'Fira Code', Consolas, 'Courier New', monospace;
        font-size: 1.1rem;
        font-weight: bold;
    }

    /* Fixing the problem with ul and li elements */
    ul {
        list-style-type: disc;  /* Ensures the default bullet style */
        margin-left: 2rem;      /* Adds left indentation for the list */
        padding-left: 1.5rem;   /* Adds extra padding inside the list */
    }

    li {
        margin-bottom: 0.5rem; /* Adds space between list items */
    }

    .image-container {
        display: flex; 
        justify-content: center; /* Center images */
        gap: 20px; /* Space between images */
    }
    .image-container img {
        width: 50%; /* Adjust width */
        height: auto; /* Maintain aspect ratio */
    }

</style>

<h1 class="h1-custom">
    Assignment 1B: Neural Implicit Surface
</h1>

<p class="mb-4">
    Welcome to the second part of our exploration of SDF! In this section, you will continue practicing coding with implicit functions, this time incorporating neural networks as your new friend! The main task for this assignment consists of two steps: first, you will construct and train a neural SDF model in Python using a Colab Jupyter Notebook. Then, you will render this model using GLSL in our WebGL shader. You will be working on both aspectsâ€”neural network training and shader-based rendering. Let's get started!
</p>

<h2 class="h2-custom">Reading</h2>
<p class="mb-4">
    Before diving into our code, you may refer to our course slides as well as the supplementary reading materials to get a comprehensive understanding of SDF and ray marching. Here is the reading list:
</p>

<ul class="list-disc pl-8 mb-4">
    <li>Course Slides on SDF Representation and Neural Implicit Surface</li>
    <li><a href="https://arxiv.org/abs/1901.05103" class="link-inline">DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation
    </a></li>
    <li><a href="https://www.youtube.com/watch?v=8pwXpfi-0bU" class="link-inline">A Haphazard Tutorial for Making Neural SDFs in Shadertoy</a></li>
    <li><a href="https://www.shadertoy.com/view/wtVyWK" class="link-inline">Neural Stanford Bunny on ShaderToy</a></li>
    <li><a href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html" class="link-inline">PyTorch Training Loop Tutorial (First Four sections)</a></li>
</ul>

<h2 class="h2-custom">Starter Code</h2>
<p>
    Please visit the following GitHub repository to get our latest starter code: <a href="https://github.com/cg-gatech/cgai" class="link-inline">https://github.com/cg-gatech/cgai</a>. Make sure to run 'git pull' to synchronize the latest version. Make sure you can access the default CGAI web page after starting the npm server. The starter code for this assignment is located in the folder <code class="code-inline">src/app/(assignment)/assignment/A1b</code>. This folder contains several files, including the main page <code class="code-inline">page.tsx</code>, the Jupyter notebook file <code class="code-inline">neural_sdf.ipynb</code>, the GLSL shader <code class="code-inline">fragment.glsl</code>, and several mesh files. Your implementation will focus on <code class="code-inline">neural_sdf.ipynb</code> and <code class="code-inline">fragment.glsl</code>.
</p>

<p>
To view the default initial effect for this assignment, you can either use the navigation bar by clicking Assignments and then Assignment 1b, or directly access the URL: <a href="http://localhost:3000/assignment/A1b" class="link-inline">http://localhost:3000/assignment/A1b</a> (Note that the port number may vary depending on the available ports on your local computer). After successfully completing the setup, you should see a blank window.
</p>

<h2 class="h2-custom">Requirements</h2>
<p class="mb-4">
For this assignment, you are expected to implement two main components to generate a neural SDF and then render it in a GLSL environment with ray marching. We will briefly discuss each component as follows.
</p>

<h3 class="h3-custom">Step 1: Neural SDF Creation</h3>
<p class="mb-4">
In this step, you are asked to create a PyTorch dataset class named <code>NeuralSDFDataset</code> which loads a 3D mesh with <code>.obj</code> format and sample data points around it for training. After this, you will create a network to train Neural SDF. Finish the training loop and train your network. Your implementation will focus on <code class="code-inline">neural_sdf.ipynb</code>.
</p>

<h3 class="h4-custom">Step 1.1 Preparation</h3>
<p class="mb-4">    
    Upload the Notebook file <code>neural_sdf.ipynb</code> to Google Colab. We prepared a quick tutorial for you for this step in <code>Tutorials/Google Colab Tutorial</code>, please read it carefully and follow the steps. Make sure to run all the cells before Step 1.2. These cells will install required packages and compile helper functions we shall need later in other steps.
</p>

<h3 class="h4-custom">Step 1.2 NeuralSDFDataset</h3>
<p class="mb-4">    
    In this step, you will implement a <code>NeuralSDFDataset</code> class. We will follow the the way Neural SDF paper sample training points where the majority of points are sampled near the mesh surface while a small amount are sampled in the space of a unit sphere around the shape. We will implement this step by using the <code>mesh_to_sdf</code> package. In our starter code, we've provided the code for loading the mesh with path <code>mesh_path</code> and sample <code>sample_num</code> number of points using <code>sample_sdf_near_surface</code> function from <code>mesh_to_sdf</code> package.
</p></br>

<p class="mb-4"></p>
    <em>[Your implementation]</em> For your implementation, you will need to implement the step to convert sampled points in type <code>numpy ndarray</code> to <code>torch tensor</code> by using the <code>torch.from_numpy</code> function. Since we are using Colab where GPU is available, you will put those tensors to <code>CUDA</code> by using <code>.to(device)</code>. The converted device tensors should be stored in self.points and self.sdf in separate.
</p></br>

<p class="mb-4">
    <em>[Checkpoint]</em> After finishing this step, you can check the correctness of your implementation by plotting the point cloud in the next block. The expected result for a bunny/cow is as below.
</p>    

<div class="image-container">
    <img src="/assignments/A1b_img/bunny.png" alt="Image 1">
    <img src="/assignments/A1b_img/cow.png" alt="Image 2">
</div>


<h3 class="h4-custom">Step 1.3 Network Structure</h3>
<p class="mb-4">    
    After finishing the creation of your training dataset, you will be tasked to create a neural network class named <code>NeuralSDF</code>. This step consists of two substeps: (1) implementing the constructor and the forward function for the sine-based neural-network layer defined in <code>SineLayer</code>, and (2) implementing the constructor for the neural network architecutre defined in <code>NeuralSDF</code>.

    (1) You are tasked to fill in the constructor of the <code>SineLayer</code> class. This requires you to first create a Linear layer namd <code>self.fc</code> with input features size <code>in_features</code>
    and output feature size <code>out_features</code>. </br></br>
    <!-- (2) You should fill in the <code>forward</code> function. If <code>is_last</code> is True, then you should not apply any activation functions (i.e. sin activation) or skip connections to this layer.
    If <code>is_first</code> is True, then you should apply the sin activation function but not the skip connection. Otherwise, you should apply both sin activation and skip connection. </br>
    For sin activation, it should be in form <code>sin(omega * f(x))</code> where <code>omega</code> being sin activation frequency and <code>f(x)</code> being the output of linear layer. </br>
    For skip connection, it should be in form <code>current_layer(x) / skip_weight + x</code> where <code>x</code> being the input to current layer, <code>current_layer</code> being <code>sin(omega * f(x))</code>
    and <code>skip_weight</code> is given in the class constructor. </br>
    </br> -->

    Next, you are asked to fill in the <code>forward</code> function of <code>SineLayer</code>. You should consider three cases in your implementation:
    <ul>
        <li>For the first layer in the network (i.e., <code>is_first</code> is True), you should apply the sine activation function but not the skip connection. Otherwise, you should apply both sin activation and skip connection. </li>
        <li>If <code>is_last</code> is True, then you should not apply any activation functions (i.e. sin activation) or skip connections to this layer.</li>
        <li>Otherwise, you should apply both the sin actiation and the skip connection</li>
    </ul>
    For sin activation, it should be in form sin(&omega; &sdot; f(x))  where &omega; being sin activation frequency and <code>f(x)</code> being the output of linear layer. </br>
    For skip connection, it should be in form current_layer(x) / skip_weight + x where x being the input to current layer, current_layer being sin(&omega; &sdot; f(x))
    and skip_weight is given in the class constructor. </br></br>

    (2) After finishing the <code>SineLayer</code> class, you will move on to implement the network structure in the <code>NeuralSDF</code> class. You should use the <code>SineLayer</code> class you have implemented from the previous substep to create your network structure.     Your task is to append every layer to the list defined by <code>self.network</code>, by following the following guidance:
     
    <ul>
        <li> Use <code>is_first=True</code> for the first layer and <code>is_first=False</code> otherwise. Use <code>is_last=True</code> for the last layer and <code>is_last=False</code> otherwise. </li>
        <li> You should create one first layer which has input feature size <code>in_features</code> and output feature size <code>hidden_features</code>. </li>
        <li> You should then create <code>hidden_layers</code> number of hidden layers with both input and output feature size of <code>hidden_features</code>. </li>
        <li> Finally, you should create the last layer with input features size <code>hidden_features</code> and output features size being 1. You should use the skip weights being set to <code>skip_weight=sqrt(i+1)</code> where <code>i</code> is the current index of hidden layer. </li>
    </ul>
</p>

<h3 class="h4-custom">Step 1.4 Train Your Network</h3>
<p class="mb-4">
    After creating the network structure, you are tasked to train your neural network. You will use Mean Squared Loss (MSE) as your loss function. Remember to zero the grad in your optimizer at the start of each iteration and propagates the loss backward at the end of each iteration. Read the PyTorch tutorials from both the PyTorch official website and our CGAI website.</br>
    <br>
    Now, start to train your network! You should observe the loss drop from the print. The entire process is expected to converge around 10,000 epoches (~20 print iterations), which usually takes several minutes on Colab. Note that we intentionally reduce the network size for a fast training process. Feel free to enlarge the network scale for better training results by tuning the provided hyperparameters before the train_neuralSDF function call. 
</p>


<h3 class="h3-custom">Step 2: Copy Network Weights to Shader</h3>
<p class="mb-4">
    Run the last cell in your notebook. Be sure to run this after the training loop finishs. Copy the text printed out in your notebook and paste them to <code>sdfBunny</code> for bunny and <code>sdfCow</code> for cow. You should now see your trained result on your screen. (Remember to refresh the browser page if you changed your code).
</p>

<h3 class="h3-custom">Step 3: Scene SDF</h3>
<p class="mb-4">
In this step, you are tasked with constructing the scene's SDF using the two neural SDF objects. You will need to position these two objects appropriately according to the instructions in the starter code comment. The final SDF function should return the minimum distance to any neural implicit surface in the scene.
</p>

<h3 class="h3-custom">Step 4: Ray Marching</h3>
<p class="mb-4">
In this step, you are asked to implement the ray marching algorithm to render the SDF scene. You are allowed to reuse your previous implementation in A1a for this function.
</p>

<h3 class="h3-custom">Step 5: Normal Calculation</h3>
<p class="mb-4">
In this step, you will calculate the surface normal at a given point using the finite difference method. You are allowed to reuse your previous implementation in A1a for this function.
</p>

<h3 class="h3-custom">Step 6: Lighting and Coloring</h3>
<p class="mb-4">
In this step, you are asked to color the objects to achieve realistic lighting effects. You are also tasked to assign a unique color to each neural SDF object in the scene based on its position or type. <em>We do not ask for a perfect match of our given video. You may pick any color you like for the rendering of these two objects.</em>

Once you have implemented all these steps, you should be able to observe the two neural SDF models (bunny and cow) as shown in the video below. 
</p>

<video controls autoplay loop muted>
    <source src="/assignments/a1b-ref.mp4" type="video/mp4">
    Your browser does not support the video tag.
</video>

<h2 class="h2-custom">Creative Expression</h2>
In the Creative Expression section of this assignment, you are encouraged to train your customized neural SDF model. You may either use one of the meshes provided in our starter code, or you may download a new mesh and train its neural SDF model in Colab. You may adjust the size of the network (e.g., the number of layers, the number of weights, etc.) to improve the appearance of your neural SDF model. The creative expression theme for this assignment is <strong>A Tangible Neural Network</strong>.

<h2 class="h2-custom">Submission</h2>
<ul class="list-disc pl-8 mb-4">
    <li>Your source code <code class="code-inline">neural_sdf.ipynb</code> and <code class="code-inline">fragment.glsl</code></li>
    <li>Your default ray-marching video after completing the six steps</li>
    <li>Your customized video with your own neural SDF objects for creative expression</li>
    <li>A concise technical explanation of your implementation</li>
</ul>

<h2 class="h2-custom">Grading</h2>
<p>This assignment is worth a total of 8 points, with the grading criteria outlined as follows:</p>
<ul class="list-disc pl-8 mb-4">
    <li>
        <strong>Technical Contribution (7 points):</strong> The core of the grading is based on the correct implementation of the neural network architectures and their rendering. The distribution of points is as follows:
        <ul class="list-disc pl-8 mb-4">
            <li>Step 1: 4 points </li>
            <li>Step 2-6: 3 points </li>
        </ul>
    </li>
    <li>
        <strong>Creative Expression (1 point):</strong> This aspect focuses on your ability to create new SDF objects with neural networks.
    </li>
</ul>

<h2 class="h2-custom">Sharing Your Work</h2>
<p>You are encouraged to share your graphical work with the class. If you want to do so, please upload your image to the Ed Discussion post <strong>A1B Gallery: A Tangible Neural Network</strong>. This is an excellent opportunity to engage with your peers and gain recognition for your work. Share with us the blobby world you create!</p>
