{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7328294",
   "metadata": {},
   "source": [
    "## Step 1.1 Run the cells before Step 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9815e45-57bf-4565-8670-6d91c8bdb35f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9815e45-57bf-4565-8670-6d91c8bdb35f",
    "outputId": "eecd5817-1a38-4eea-8bb7-f64dc79603b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mesh_to_sdf in /usr/local/lib/python3.11/dist-packages (0.0.15)\n",
      "Requirement already satisfied: pyopengl in /usr/local/lib/python3.11/dist-packages (from mesh_to_sdf) (3.1.0)\n",
      "Requirement already satisfied: pyrender in /usr/local/lib/python3.11/dist-packages (from mesh_to_sdf) (0.1.45)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from mesh_to_sdf) (0.25.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from mesh_to_sdf) (1.6.1)\n",
      "Requirement already satisfied: freetype-py in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (2.5.1)\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (2.36.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (3.4.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (11.1.0)\n",
      "Requirement already satisfied: pyglet>=1.4.10 in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (2.1.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (1.13.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (1.17.0)\n",
      "Requirement already satisfied: trimesh in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (4.6.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->mesh_to_sdf) (2025.1.10)\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->mesh_to_sdf) (24.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->mesh_to_sdf) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->mesh_to_sdf) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->mesh_to_sdf) (3.5.0)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
      "  xserver-common\n",
      "The following NEW packages will be installed:\n",
      "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
      "  xserver-common xvfb\n",
      "0 upgraded, 9 newly installed, 0 to remove and 18 not upgraded.\n",
      "Need to get 7,815 kB of archives.\n",
      "After this operation, 11.9 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.12 [28.7 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.12 [864 kB]\n",
      "Fetched 7,815 kB in 1s (7,393 kB/s)\n",
      "Selecting previously unselected package libfontenc1:amd64.\n",
      "(Reading database ... 124950 files and directories currently installed.)\n",
      "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
      "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
      "Selecting previously unselected package libxfont2:amd64.\n",
      "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
      "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
      "Selecting previously unselected package libxkbfile1:amd64.\n",
      "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
      "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
      "Selecting previously unselected package x11-xkb-utils.\n",
      "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
      "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
      "Selecting previously unselected package xfonts-encodings.\n",
      "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
      "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
      "Selecting previously unselected package xfonts-utils.\n",
      "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
      "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
      "Selecting previously unselected package xfonts-base.\n",
      "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
      "Unpacking xfonts-base (1:1.0.5) ...\n",
      "Selecting previously unselected package xserver-common.\n",
      "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.12_all.deb ...\n",
      "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
      "Selecting previously unselected package xvfb.\n",
      "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.12_amd64.deb ...\n",
      "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
      "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
      "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
      "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
      "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
      "Setting up x11-xkb-utils (7.7+5build4) ...\n",
      "Setting up xfonts-utils (1:7.7+6build2) ...\n",
      "Setting up xfonts-base (1:1.0.5) ...\n",
      "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
      "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "Collecting pyvirtualdisplay\n",
      "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: pyvirtualdisplay\n",
      "Successfully installed pyvirtualdisplay-3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mesh_to_sdf\n",
    "!apt-get install xvfb\n",
    "!pip install pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd34ee-1d7b-47f7-b1c0-9b8bebe3c410",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78dd34ee-1d7b-47f7-b1c0-9b8bebe3c410",
    "outputId": "1052f7fd-6807-4d78-f708-19ac97516e7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7897eadbe950>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "from IPython.display import display\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from mesh_to_sdf import sample_sdf_near_surface\n",
    "import trimesh\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3476f642",
   "metadata": {},
   "source": [
    "## Step 1.2 NeuralSDFDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb098a6-acb2-435e-affd-1f94d2385ec7",
   "metadata": {
    "id": "0cb098a6-acb2-435e-affd-1f94d2385ec7"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 1.2: Finish the NeuralSDFDataset class that loads a mesh with path `mesh_path` and sample points\n",
    "\"\"\"\n",
    "\n",
    "class NeuralSDFDataset(Dataset):\n",
    "    def __init__(self, mesh_path, sample_num, device='cuda'):\n",
    "        \"\"\"\n",
    "        (1) You will first use a package called `trimesh` (it's already imported in Step 1.1) to load a `.obj` file with path <code>mesh_path</code>\n",
    "        (2) We use sample_num points sampled non uniformly around the surface using non-uniform sampling method `sample_sdf_near_surface`. \n",
    "        (3) After sampling points, you will convert sampled points in type `numpy ndarray` to `torch tensor` by using the `torch.from_numpy` function.\n",
    "            Since we are using Colab where GPU is available, you will put those tensors to CUDA by using `.to(device)`.\n",
    "        \"\"\"\n",
    "        ### you implementation starts\n",
    "        \n",
    "        ### you implementation ends\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1 # we are not using this\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.points, self.sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e00e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper method for test result of the sampled points from your dataset class.\n",
    "def test_dataset(sdf_loader_test):\n",
    "  points, sdf = next(iter(sdf_loader_test))\n",
    "  points =  points.cpu().detach().numpy().squeeze(0)\n",
    "  sdf = sdf.cpu().detach().numpy().squeeze()\n",
    "  norm = plt.Normalize(vmin=np.min(sdf), vmax=np.max(sdf))\n",
    "  colors = plt.cm.coolwarm(norm(sdf))\n",
    "  fig = plt.figure(figsize=(8, 6))\n",
    "  ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "  sc = ax.scatter(points[:, 0], points[:, 1], points[:, 2], c=sdf, cmap='coolwarm', marker='o')\n",
    "\n",
    "  cbar = plt.colorbar(sc, ax=ax, shrink=0.5)\n",
    "  cbar.set_label(\"SDF Value\")\n",
    "\n",
    "  ax.set_xlabel(\"X\")\n",
    "  ax.set_ylabel(\"Y\")\n",
    "  ax.set_zlabel(\"Z\")\n",
    "  ax.set_title(\"3D Point Cloud Visualization with SDF Values\")\n",
    "  ax.view_init(elev=0, azim=0)\n",
    "  plt.show()\n",
    "\n",
    "  \n",
    "sample_num = 10000\n",
    "device='cuda'\n",
    "mesh_path=\"cow.obj\" ### Change to bunny.obj if needed.\n",
    "\n",
    "sdf_test = NeuralSDFDataset(mesh_path, sample_num, device=device)\n",
    "sdf_loader_test = DataLoader(sdf_test, num_workers=0)\n",
    "test_dataset(sdf_loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d9f5e",
   "metadata": {},
   "source": [
    "## Step 1.3 Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db29c56f-6b6c-47f6-8ba5-c40fb6741742",
   "metadata": {
    "id": "db29c56f-6b6c-47f6-8ba5-c40fb6741742"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sine layer\n",
    "\"\"\"\n",
    "\n",
    "class SineLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Default sin activation frequency w0 is set to be 30, feel free to play with it.\n",
    "    However, we set this to be 15 by default due to our network is much smaller that suffers from learning high frequency features.\n",
    "    If you have time, make the hidden layers to 512 width with 5 depth, then checkout the difference.\n",
    "\n",
    "    By default, first layer's weight is initialized differently as suggested in Sec.3.2 in the original paper. We use is_first flag to\n",
    "    check whether we should init the weights differently.\n",
    "\n",
    "    We use linear layer as the last layer without any activation functions since SDF values shouldn't be limited to a certain range.\n",
    "    We use is_last flag to check if we should use activation functions or not.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, is_last=False, w0=15, skip_weight=1):\n",
    "        super().__init__()\n",
    "        self.w0 = w0\n",
    "        self.is_first = is_first\n",
    "        self.is_last = is_last\n",
    "        self.skip_weight = skip_weight\n",
    "\n",
    "        self.in_features = in_features\n",
    "\n",
    "        ### your implementation starts\n",
    "\n",
    "        ### your implementation ends\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        initialize the weights for first layer and other layers following last paragraph in Sec.3.2\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.fc.weight.uniform_(-1. / self.in_features,\n",
    "                                             1. / self.in_features)\n",
    "            else:\n",
    "                self.fc.weight.uniform_(-np.sqrt(6 / self.in_features) / self.w0,\n",
    "                                             np.sqrt(6 / self.in_features) / self.w0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Use sin activation function for fully connected layers, notice we add a skip connection to make network learns the shape easier since\n",
    "        we don't have enough neurons.\n",
    "        \"\"\"\n",
    "        ### your implementation starts\n",
    "\n",
    "        ### your implementation ends\n",
    "\n",
    "\"\"\"\n",
    "Step 1.3: Network structure\n",
    "\"\"\"\n",
    "class NeuralSDF(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, w0=30):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        Weights in first layer should be initialized differently from other layers (See last sentence in Sec.3.2 in SIREN paper)\n",
    "        Notice we don't use activation for the final layer.\n",
    "        \"\"\"\n",
    "        self.net = []\n",
    "        self.w0 = w0\n",
    "        self.hidden_features = hidden_features\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.out_features = out_features\n",
    "        self.in_features = in_features\n",
    "\n",
    "        ### your implementation starts\n",
    "\n",
    "        ### your implementation ends\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.net(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c90b11e",
   "metadata": {},
   "source": [
    "## Step 1.4 Train Your Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb654774-d60f-4f06-b374-9b5cc8ebe840",
   "metadata": {
    "id": "fb654774-d60f-4f06-b374-9b5cc8ebe840"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We train neuralSDF for 20000 epochs, feel free to train more if time allowed.\n",
    "`lr` is set to 1e-4, feel free to play around with this.\n",
    "\"\"\"\n",
    "def train_neuralSDF(dataloader, hidden_features, hidden_layers, w0, lr=1e-4, iterations=10000, device='cuda'):\n",
    "    model = NeuralSDF(in_features=3, out_features=1, hidden_features=hidden_features, hidden_layers=hidden_layers, w0=w0).to(device)\n",
    "    optimizer = torch.optim.Adam(lr=lr, params=model.parameters(), weight_decay=.0)\n",
    "    data, labels = next(iter(dataloader))\n",
    "\n",
    "    for epoch in range(iterations):\n",
    "\n",
    "        ### your implementation starts\n",
    "\n",
    "        ### your implementation ends\n",
    "        if epoch % 500 == 0:\n",
    "            print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195eb13-77a7-45b5-baf1-d5b471cd4828",
   "metadata": {
    "id": "9195eb13-77a7-45b5-baf1-d5b471cd4828"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sample_num: total points sampled (feel free to increase this if needed)\n",
    "mesh_path: relative path to .obj file location\n",
    "\"\"\"\n",
    "\n",
    "sample_num = 300000  ### total number of points sampled as training points, feel free to change this.\n",
    "device='cuda'\n",
    "mesh_path=\"cow.obj\" ### mesh path to your mesh,\n",
    "\n",
    "sdf = NeuralSDFDataset(mesh_path, sample_num, device=device)\n",
    "sdfloader = DataLoader(sdf, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a405f-0728-407b-935a-af706e779e49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "438a405f-0728-407b-935a-af706e779e49",
    "outputId": "206c2b72-333b-4fc7-c85b-3bda7f70e024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.033336713910102844\n",
      "Epoch 501, Loss: 0.000399589043809101\n",
      "Epoch 1001, Loss: 0.00013242478598840535\n",
      "Epoch 1501, Loss: 7.75775988586247e-05\n",
      "Epoch 2001, Loss: 5.152824451215565e-05\n",
      "Epoch 2501, Loss: 3.68651635653805e-05\n",
      "Epoch 3001, Loss: 2.8019421733915806e-05\n",
      "Epoch 3501, Loss: 2.2144828108139336e-05\n",
      "Epoch 4001, Loss: 1.809777313610539e-05\n",
      "Epoch 4501, Loss: 1.5428755432367325e-05\n",
      "Epoch 5001, Loss: 1.3461575690598693e-05\n",
      "Epoch 5501, Loss: 1.1997304682154208e-05\n",
      "Epoch 6001, Loss: 1.0885492883971892e-05\n",
      "Epoch 6501, Loss: 1.0055349775939249e-05\n",
      "Epoch 7001, Loss: 9.42936912906589e-06\n",
      "Epoch 7501, Loss: 8.932043783715926e-06\n",
      "Epoch 8001, Loss: 8.521431482222397e-06\n",
      "Epoch 8501, Loss: 8.263333256763872e-06\n",
      "Epoch 9001, Loss: 8.136436008499004e-06\n",
      "Epoch 9501, Loss: 7.687694960623048e-06\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "hidden_features: hidden layer width.\n",
    "hidden_layers: hidden layer depth.\n",
    "w0: Activation frequency. We suggest 15 for our given examples.\n",
    "\n",
    "Feel free to play around with these parameters.\n",
    "\"\"\"\n",
    "hidden_features = 16 ### hidden layer width, feel free to change\n",
    "hidden_layers = 2 ### hidden layer depth, feel free to change\n",
    "w0 = 15 ### activation function frequency, feel free to change\n",
    "iterations = 10000 ### total number of training iterations, feel free to change\n",
    "lr = 1e-4 ### learning rate, feel free to change\n",
    "\n",
    "neural_sdf = train_neuralSDF(sdfloader, hidden_features = hidden_features, hidden_layers = hidden_layers, w0 = w0, lr=lr, iterations=iterations, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71626b5",
   "metadata": {},
   "source": [
    "## Step 2 Copy Network Weights to Shader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fcd78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Modified based on https://www.shadertoy.com/view/wtVyWK\n",
    "Will be used for outputing network weights to matrices and visualize in our shader\n",
    "\"\"\"\n",
    "import re\n",
    "\n",
    "### Helper function for convert pytorch cuda tensor to numpy arrays\n",
    "def dump_data(dat):\n",
    "  dat = dat.cpu().detach().numpy()\n",
    "  return dat\n",
    "\n",
    "### Print a vector to a form that's usable in fragement shader\n",
    "def print_vec4(ws):\n",
    "  vec = \"vec4(\" + \",\".join([\"{0:.2f}\".format(w) for w in ws]) + \")\"\n",
    "  vec = re.sub(r\"\\b0\\.\", \".\", vec)\n",
    "  return vec\n",
    "\n",
    "### Print a matrix to a form that's usable in fragement shader\n",
    "def print_mat4(ws):\n",
    "  mat = \"mat4(\" + \",\".join([\"{0:.2f}\".format(w) for w in np.transpose(ws).flatten()]) + \")\"\n",
    "  mat = re.sub(r\"\\b0\\.\", \".\", mat)\n",
    "  return mat\n",
    "\n",
    "### Since we know networks are just matrices and vectors, this function converts our network to matrices and vectors that \n",
    "### can be compiled in fragement shader. \n",
    "def serialize_to_shadertoy(network, varname):\n",
    "  omega = network.w0\n",
    "  chunks = int(network.hidden_features/4)\n",
    "  lin = network.net[0].fc\n",
    "  in_w = dump_data(lin.weight)\n",
    "  in_bias = dump_data(lin.bias)\n",
    "  om = omega\n",
    "  for row in range(chunks):\n",
    "    line = \"vec4 %s0_%d=sin(\" % (varname, row)\n",
    "    for ft in range(network.in_features):\n",
    "        feature = x_vec = in_w[row*4:(row+1)*4,ft]*om\n",
    "        line += (\"p.%s*\" % [\"y\",\"z\",\"x\"][ft]) + print_vec4(feature) + \"+\"\n",
    "    bias = in_bias[row*4:(row+1)*4]*om\n",
    "    line += print_vec4(bias) + \");\"\n",
    "    print(line)\n",
    "\n",
    "  #hidden layers\n",
    "  for layer in range(network.hidden_layers):\n",
    "    layer_w = dump_data(network.net[layer+1].fc.weight)\n",
    "    layer_bias = dump_data(network.net[layer+1].fc.bias)\n",
    "    for row in range(chunks):\n",
    "      line = (\"vec4 %s%d_%d\" % (varname, layer+1, row)) + \"=sin(\"\n",
    "      for col in range(chunks):\n",
    "        mat = layer_w[row*4:(row+1)*4,col*4:(col+1)*4]*omega\n",
    "        line += print_mat4(mat) + (\"*%s%d_%d\"%(varname, layer, col)) + \"+\\n    \"\n",
    "      bias = layer_bias[row*4:(row+1)*4]*omega\n",
    "      line += print_vec4(bias)+\")/%0.1f+%s%d_%d;\"%(sqrt(layer+1), varname, layer, row)\n",
    "      print(line)\n",
    "\n",
    "  #output layer\n",
    "  out_w = dump_data(network.net[-1].fc.weight)\n",
    "  out_bias = dump_data(network.net[-1].fc.bias)\n",
    "  for outf in range(network.out_features):\n",
    "    line = \"return \"\n",
    "    for row in range(chunks):\n",
    "      vec = out_w[outf,row*4:(row+1)*4]\n",
    "      line += (\"dot(%s%d_%d,\"%(varname, network.hidden_layers, row)) + print_vec4(vec) + \")+\\n    \"\n",
    "    print(line + \"{:0.3f}\".format(out_bias[outf])+\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fcebc6-c43a-4ff9-9a5f-622be22d03cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0fcebc6-c43a-4ff9-9a5f-622be22d03cf",
    "outputId": "e2278819-13b7-49f9-c5e5-294a63d8b641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec4 f0_0=sin(p.y*vec4(-2.27,-.42,3.11,1.32)+p.z*vec4(4.14,-.04,2.50,-4.02)+p.x*vec4(2.39,3.72,-4.08,-1.55)+vec4(-2.69,5.49,8.15,5.66));\n",
      "vec4 f0_1=sin(p.y*vec4(1.94,-3.90,1.04,-3.08)+p.z*vec4(-1.11,1.31,3.88,-.57)+p.x*vec4(-3.48,-.79,3.44,-1.87)+vec4(8.85,1.33,3.54,-4.91));\n",
      "vec4 f0_2=sin(p.y*vec4(-.50,-.01,-2.68,-.59)+p.z*vec4(2.72,1.88,-.77,-3.06)+p.x*vec4(1.83,-.55,.87,-3.82)+vec4(-1.80,2.33,7.17,-2.31));\n",
      "vec4 f0_3=sin(p.y*vec4(2.75,1.26,-2.49,-1.01)+p.z*vec4(-2.49,2.80,3.07,-.10)+p.x*vec4(-.73,-3.07,-2.46,1.27)+vec4(-4.81,-6.38,6.50,1.89));\n",
      "vec4 f1_0=sin(mat4(.12,.20,-.25,-.25,.53,.09,-.55,-.15,-.55,.66,.15,.32,-.29,.04,-.12,-.27)*f0_0+\n",
      "    mat4(-.04,.22,-.01,-.70,-.43,-.02,.41,.76,-.08,-.03,-.14,.54,-.10,.74,.15,-.07)*f0_1+\n",
      "    mat4(.48,.38,-.31,.43,.51,-.11,.85,-.07,.46,-.35,.96,-.49,-.64,-.43,.21,.27)*f0_2+\n",
      "    mat4(-.14,-.17,.02,.27,.12,.33,.03,-.25,-.28,-.15,.16,-.36,.60,.74,.48,-.09)*f0_3+\n",
      "    vec4(-.22,-.57,-3.53,-.77))/1.0+f0_0;\n",
      "vec4 f1_1=sin(mat4(-.23,-.29,.71,-.49,.39,.20,.37,-.16,-.36,-.36,.61,-.11,-.34,.16,.31,-.00)*f0_0+\n",
      "    mat4(-.17,.09,.28,-.04,-.01,-.03,-.28,.01,.05,-.26,-.15,-.27,.11,-.21,.32,.16)*f0_1+\n",
      "    mat4(-.09,-.24,.41,.42,-.28,-.36,-.03,-.06,-.25,.35,-.38,.11,-.33,-.21,-.68,.21)*f0_2+\n",
      "    mat4(-.02,.06,.71,-.27,-.13,.48,.37,-.26,-.01,.21,-.42,-.34,-.49,.12,-.23,.34)*f0_3+\n",
      "    vec4(-.73,1.89,-2.57,-1.95))/1.0+f0_1;\n",
      "vec4 f1_2=sin(mat4(-.02,.05,.45,.12,.54,-.43,.85,-.15,.62,.02,-.10,.38,.12,.07,.45,-.26)*f0_0+\n",
      "    mat4(-.46,-.01,-.43,.30,.33,.71,-.26,-.59,-.17,-.23,.41,-.13,-.15,.12,.22,.26)*f0_1+\n",
      "    mat4(-.25,-.35,.28,-.00,-.25,-.31,.08,.48,-.52,.43,.92,.16,.15,.14,-.09,-.19)*f0_2+\n",
      "    mat4(-.36,-.23,-.21,.06,.49,-.01,-.52,.36,-.04,-.50,-.38,.26,.13,-.39,-.53,.00)*f0_3+\n",
      "    vec4(-1.71,-3.64,3.17,2.93))/1.0+f0_2;\n",
      "vec4 f1_3=sin(mat4(-.01,.19,.19,.33,-.03,-.24,-.77,-.32,.00,.19,.06,.55,.15,.03,-.02,-.54)*f0_0+\n",
      "    mat4(-.12,-.09,.40,-.28,.09,.29,-.11,.03,-.14,.03,-.37,-.45,-.06,.16,-.06,.56)*f0_1+\n",
      "    mat4(.39,.21,.59,.28,.05,-.06,-.28,-.25,-.90,-.16,.40,.02,-.01,-.28,.61,-.51)*f0_2+\n",
      "    mat4(-.16,.01,.16,.20,.09,.02,-.05,-.44,-.04,.17,.01,-.45,-.91,.08,-.15,.00)*f0_3+\n",
      "    vec4(-1.57,1.73,3.40,-2.84))/1.0+f0_3;\n",
      "vec4 f2_0=sin(mat4(-.46,.21,.04,-.05,-.58,.23,.33,-.13,.54,-.69,-.15,-.76,-.23,.19,-.46,.16)*f1_0+\n",
      "    mat4(-.16,-.12,.08,-.40,.32,-.33,.27,-.55,-.26,.29,-.41,.47,-.57,.39,-.42,-.06)*f1_1+\n",
      "    mat4(.34,-.14,-.55,-.09,-.01,-.05,.05,.94,.32,.22,.17,.11,.09,-.43,-.02,-.30)*f1_2+\n",
      "    mat4(-.47,-.04,.18,-.23,.29,-.16,-.30,-.26,-.09,-.21,-.38,-.88,.23,.33,-.19,-.41)*f1_3+\n",
      "    vec4(-.93,-.24,1.03,3.67))/1.4+f1_0;\n",
      "vec4 f2_1=sin(mat4(-.34,.20,-.23,.22,-.32,-.19,.15,-.23,-.03,.15,.12,.09,.44,-.49,-.22,.43)*f1_0+\n",
      "    mat4(.27,.31,.09,-.11,-.24,.12,.54,-.12,-.25,-.03,-.15,-.04,.37,.19,-.39,.43)*f1_1+\n",
      "    mat4(-.51,.67,-.41,.65,-.01,-.04,-.17,-.45,-.43,-.29,-.21,.21,.20,.14,.86,-.22)*f1_2+\n",
      "    mat4(-.10,.37,.31,-.23,-.71,-.24,.74,.21,.38,.33,.35,.46,.02,-.13,-.24,.14)*f1_3+\n",
      "    vec4(2.21,2.50,.61,2.01))/1.4+f1_1;\n",
      "vec4 f2_2=sin(mat4(-.46,.51,.01,.14,-.40,-.63,-.09,.50,-.39,.05,-.35,-.23,.21,-.14,-.09,-.59)*f1_0+\n",
      "    mat4(.08,-.13,.43,-.31,-.50,.10,-.23,-.42,.16,.10,-.19,.18,.06,.65,-.39,-.02)*f1_1+\n",
      "    mat4(.17,.19,.50,.01,-.64,-.12,-.66,-.54,-.33,.06,-.71,-.39,.44,-.25,.54,.37)*f1_2+\n",
      "    mat4(.20,.68,.33,.10,-.40,.05,.00,.67,.35,-.11,.26,.45,.16,.07,-.03,.12)*f1_3+\n",
      "    vec4(-3.86,3.02,1.96,-2.09))/1.4+f1_2;\n",
      "vec4 f2_3=sin(mat4(-.05,-.13,.08,.45,-.15,-.03,-.46,-.19,.19,.18,.14,-.12,.29,.16,.29,.57)*f1_0+\n",
      "    mat4(-.41,.85,.22,.62,.43,-.19,.38,.42,.18,-.33,.41,-.18,.03,-.25,-.71,.17)*f1_1+\n",
      "    mat4(-.60,.47,.16,-.28,.62,-.08,-.44,.26,.18,.37,-.32,.33,-.27,.44,.61,-.62)*f1_2+\n",
      "    mat4(-.20,-.25,-.51,.21,.34,.26,.14,-.32,.17,.08,.08,-.25,.52,-.20,-.38,.32)*f1_3+\n",
      "    vec4(3.66,1.75,-2.43,-3.48))/1.4+f1_3;\n",
      "vec4 f3_0=sin(mat4(.35,-.27,.00,.45,.00,-.21,-.12,.25,-.26,.17,.31,.03,-.06,.61,.08,-.12)*f2_0+\n",
      "    mat4(-.10,-.67,.34,.55,.58,.03,.74,-.11,.53,-.32,.53,-.44,.64,-.48,.09,-.15)*f2_1+\n",
      "    mat4(-.31,.62,-.05,.09,.43,.35,.71,.56,-.09,-.09,-.72,-.25,.11,.13,.74,-.33)*f2_2+\n",
      "    mat4(.83,-.24,.08,.03,-.22,.10,.74,.47,-.78,.63,-.13,-.34,-.00,-.86,-.62,.41)*f2_3+\n",
      "    vec4(2.59,-3.35,.37,3.52))/1.7+f2_0;\n",
      "vec4 f3_1=sin(mat4(-.03,-.11,.85,.30,-.11,-.04,.38,-.17,-.00,.23,-.23,.10,.14,-.47,.19,.33)*f2_0+\n",
      "    mat4(-.52,.01,.15,-.62,.51,-.03,-.04,-.58,.47,.54,-.21,-.83,-.54,.60,.65,-.44)*f2_1+\n",
      "    mat4(.33,-.17,.18,.50,-.40,-.30,-.26,-.12,.56,.57,.18,.06,.17,.25,-.30,-.38)*f2_2+\n",
      "    mat4(-.18,.05,.55,.39,.33,.39,-.55,-.33,-.68,-.12,-.82,-.39,.18,-.24,-.01,-.42)*f2_3+\n",
      "    vec4(2.63,1.34,-2.69,-1.57))/1.7+f2_1;\n",
      "vec4 f3_2=sin(mat4(.00,.05,-.14,-.48,-.23,-.34,.79,-.12,-.21,.49,-.19,-.09,.75,.19,-.35,-.62)*f2_0+\n",
      "    mat4(.31,.81,.17,-.49,-.61,-.09,.90,.21,.79,.71,-.51,.21,.04,.10,.79,-.74)*f2_1+\n",
      "    mat4(-.12,.62,-.75,.39,.45,.50,.55,-.44,-.42,.18,.27,-.58,.60,.49,-.20,-.32)*f2_2+\n",
      "    mat4(-.28,-.17,.19,-.62,.56,.52,-.22,.22,.42,.05,-.63,.10,-.78,-.73,.52,-.24)*f2_3+\n",
      "    vec4(-.96,.29,-3.85,-2.47))/1.7+f2_2;\n",
      "vec4 f3_3=sin(mat4(1.02,.31,-.11,-.34,-.13,.46,.54,.13,.58,-.07,.12,-.07,.06,-.30,-.08,-.47)*f2_0+\n",
      "    mat4(.83,.03,-.05,-.28,-.84,.24,.21,-.03,-.43,.16,.24,-.36,-.15,-.16,.67,.84)*f2_1+\n",
      "    mat4(.01,-.41,-.26,.19,-.21,-.15,.18,.06,.09,-.35,.22,.31,-.01,.55,.46,-.24)*f2_2+\n",
      "    mat4(.87,.19,.57,.68,-.78,-.20,-.63,-.38,-.56,.32,-.51,-.22,-.24,-.14,.56,.44)*f2_3+\n",
      "    vec4(1.28,1.86,-.31,-1.97))/1.7+f2_3;\n",
      "vec4 f4_0=sin(mat4(-.67,-.45,-.05,.54,-.37,-.27,-.02,.55,.13,.43,-.67,-1.00,.55,-.60,-.59,.20)*f3_0+\n",
      "    mat4(-.15,.21,.30,-.05,.16,.85,.18,-.18,.19,.01,-.52,1.32,.48,-.54,.70,.06)*f3_1+\n",
      "    mat4(.41,.24,.59,-.74,-.42,-.00,-.45,.59,.11,.46,-.85,.09,-.34,-.33,-.42,.58)*f3_2+\n",
      "    mat4(-.33,.08,-.10,.31,-.10,.32,-.87,.08,.42,-.46,-1.11,-.55,.03,-.58,.49,-.29)*f3_3+\n",
      "    vec4(-1.55,-3.28,-.46,-2.52))/2.0+f3_0;\n",
      "vec4 f4_1=sin(mat4(-.30,-.02,.10,.36,-.22,.38,.00,-.33,-.19,-.40,.73,1.16,.76,-.07,-.12,-.25)*f3_0+\n",
      "    mat4(-.66,-.56,.08,.05,.18,.79,-.09,-.33,-.72,-.21,.30,-.57,-.36,-.79,.06,.27)*f3_1+\n",
      "    mat4(-.25,.44,-.15,-.58,.42,.61,-.41,.41,-.51,-.46,.24,-.29,.52,-.56,-.54,-.24)*f3_2+\n",
      "    mat4(.25,-.12,.41,.00,-.38,-.11,.04,.02,.04,-.41,.04,.79,.27,-.40,.27,.33)*f3_3+\n",
      "    vec4(-.26,.22,1.62,3.38))/2.0+f3_1;\n",
      "vec4 f4_2=sin(mat4(.04,-.14,.35,.74,-.15,.11,-.03,.12,-.01,.43,.30,.52,-.04,-.43,.17,-.29)*f3_0+\n",
      "    mat4(-.29,.20,.51,.34,-.32,-.06,-.21,.36,-1.00,.44,.45,.34,-.05,-.28,.85,.97)*f3_1+\n",
      "    mat4(.32,.08,-.30,.44,.32,-.73,-.99,.15,-1.33,.53,.29,.12,-.94,.21,.59,-.42)*f3_2+\n",
      "    mat4(-.27,.34,-.55,-.11,-.46,.51,-.05,.06,-.20,.24,-.43,-.51,.65,-.38,.08,-.39)*f3_3+\n",
      "    vec4(-1.84,1.71,1.93,2.22))/2.0+f3_2;\n",
      "vec4 f4_3=sin(mat4(-.30,.37,.12,.05,.09,.93,-.61,-.62,-.26,-.07,.91,-.77,.63,-.15,-.07,-.31)*f3_0+\n",
      "    mat4(.43,-.17,.23,.53,1.19,.03,-.76,.50,.06,-.57,.05,.60,-.31,.26,-.30,.20)*f3_1+\n",
      "    mat4(-.97,-.16,.28,-.51,.77,.77,-.10,-.39,.19,.60,.52,-.13,-.45,.03,.24,-.10)*f3_2+\n",
      "    mat4(-.15,-.00,-.01,.24,-.88,-.00,.44,.14,-1.03,-.35,.28,.19,-.15,-.08,-.75,.36)*f3_3+\n",
      "    vec4(-2.08,-.50,-2.59,-3.19))/2.0+f3_3;\n",
      "return dot(f4_0,vec4(.04,-.04,.04,-.02))+\n",
      "    dot(f4_1,vec4(-.03,.05,.04,.01))+\n",
      "    dot(f4_2,vec4(-.01,.08,.03,-.04))+\n",
      "    dot(f4_3,vec4(-.04,.05,-.04,.06))+\n",
      "    -0.202;\n"
     ]
    }
   ],
   "source": [
    "serialize_to_shadertoy(neural_sdf, 'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b3a8c-162e-4404-84a5-69737f1fd179",
   "metadata": {
    "id": "250b3a8c-162e-4404-84a5-69737f1fd179"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad48e03-b004-4a15-bebc-27ec7032af35",
   "metadata": {
    "id": "9ad48e03-b004-4a15-bebc-27ec7032af35"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
